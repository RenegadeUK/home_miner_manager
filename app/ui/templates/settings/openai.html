{% extends "base.html" %}

{% block content %}
<p style="color: var(--text-secondary); margin-bottom: 2rem;">
    Configure AI integration settings for potential future AI-powered features
    (anomaly detection, automated insights, etc.)
</p>

<!-- OpenAI Configuration -->
<div class="card" style="margin-bottom: 2rem;">
    <div class="card-header">
        <h2 class="card-title">ü§ñ OpenAI (Cloud)</h2>
    </div>
    
    <form id="openai-config-form">
        <!-- Enable Toggle -->
        <div class="form-group">
            <label class="toggle-label">
                <input type="checkbox" id="openai-enabled" name="enabled">
                <span>Enable OpenAI Integration</span>
            </label>
            <p class="form-help">Use OpenAI's GPT models for AI features</p>
        </div>
        
        <div id="openai-fields">
            <!-- API Key -->
            <div class="form-group">
                <label for="openai-api-key">OpenAI API Key <span class="required">*</span></label>
                <div class="input-with-button">
                    <input 
                        type="password" 
                        id="openai-api-key" 
                        name="api_key"
                        placeholder="sk-..." 
                        autocomplete="off"
                    >
                    <button type="button" class="btn btn-secondary" onclick="toggleApiKeyVisibility('openai')" aria-label="Toggle API key visibility">
                        <i class="fas fa-eye" id="openai-eye-icon"></i>
                    </button>
                    <button type="button" class="btn btn-secondary" onclick="testOpenAIConnection()" aria-label="Test connection">
                        <i class="fas fa-plug"></i> Test
                    </button>
                </div>
                <p class="form-help">
                    Get your API key from <a href="https://platform.openai.com/api-keys" target="_blank" rel="noopener">OpenAI Platform</a>.
                    Your key is stored securely and never shared.
                </p>
                <div id="openai-key-status" style="margin-top: 0.5rem; display: none;"></div>
            </div>
            
            <!-- Model Selection -->
            <div class="form-group">
                <label for="openai-model">Model</label>
                <select id="openai-model" name="model">
                    <option value="gpt-4o">GPT-4o (Recommended)</option>
                    <option value="gpt-4o-mini">GPT-4o Mini (Cheaper)</option>
                    <option value="gpt-4-turbo">GPT-4 Turbo</option>
                </select>
                <p class="form-help">
                    GPT-4o provides best quality. GPT-4o-mini is faster and cheaper for simple queries.
                </p>
            </div>
            
            <!-- Max Tokens -->
            <div class="form-group">
                <label for="openai-max-tokens">Max Response Tokens</label>
                <input type="number" id="openai-max-tokens" name="max_tokens" value="1000" min="100" max="4000" step="100">
                <p class="form-help">Maximum length of AI responses. Higher = longer answers but more cost.</p>
            </div>
        </div>
        
        <!-- Save Button -->
        <button type="submit" class="btn btn-primary">
            <i class="fas fa-save"></i> Save OpenAI Configuration
        </button>
    </form>
</div>

<!-- Ollama Configuration -->
<div class="card">
    <div class="card-header">
        <h2 class="card-title">ü¶ô Ollama (Local)</h2>
    </div>
    
    <form id="ollama-config-form">
        <!-- Enable Toggle -->
        <div class="form-group">
            <label class="toggle-label">
                <input type="checkbox" id="ollama-enabled" name="enabled">
                <span>Enable Ollama Integration</span>
            </label>
            <p class="form-help">Use local Ollama models for AI features (no API costs)</p>
        </div>
        
        <div id="ollama-fields">
            <!-- Base URL -->
            <div class="form-group">
                <label for="ollama-base-url">Ollama Base URL <span class="required">*</span></label>
                <div class="input-with-button">
                    <input 
                        type="text" 
                        id="ollama-base-url" 
                        name="base_url"
                        placeholder="http://localhost:11434/v1" 
                        value="http://localhost:11434/v1"
                    >
                    <button type="button" class="btn btn-secondary" onclick="testOllamaConnection()" aria-label="Test connection">
                        <i class="fas fa-plug"></i> Test
                    </button>
                </div>
                <div id="ollama-key-status" style="display: none; margin-top: 0.5rem;"></div>
                <p class="form-help">
                    URL to your Ollama instance. Use <code>http://ollama:11434/v1</code> if running in Docker.
                    <a href="https://ollama.ai" target="_blank" rel="noopener">Install Ollama ‚Üí</a>
                </p>
            </div>
            
            <!-- Ollama Model -->
            <div class="form-group">
                <label for="ollama-model">Model</label>
                <select id="ollama-model" name="ollama_model">
                    <option value="qwen2.5-coder:7b">Qwen 2.5 Coder 7B (Recommended - Function Calling)</option>
                    <option value="llama3.1:8b">Llama 3.1 8B (Good Balance)</option>
                    <option value="mistral:7b">Mistral 7B (Fast)</option>
                    <option value="qwen2.5:7b">Qwen 2.5 7B (General)</option>
                    <option value="custom">Custom Model...</option>
                </select>
                <p class="form-help">
                    Choose a model or enter a custom one. Models with function calling support work best.
                </p>
            </div>
            
            <!-- Custom Model Name (hidden by default) -->
            <div class="form-group" id="ollama-custom-model-group" style="display: none;">
                <label for="ollama-custom-model">Custom Model Name</label>
                <input 
                    type="text" 
                    id="ollama-custom-model" 
                    name="custom_model"
                    placeholder="e.g., llama3.1:70b"
                >
                <p class="form-help">Enter the exact model name from <code>ollama list</code></p>
            </div>
            
            <!-- Max Tokens -->
            <div class="form-group">
                <label for="ollama-max-tokens">Max Response Tokens</label>
                <input type="number" id="ollama-max-tokens" name="max_tokens" value="1000" min="100" max="4000" step="100">
                <p class="form-help">Maximum length of AI responses.</p>
            </div>
            
            <div class="alert alert-info">
                <i class="fas fa-info-circle"></i>
                <strong>Using Ollama:</strong> Run <code>ollama pull qwen2.5-coder:7b</code> to download the model first.
                See <a href="https://github.com/ollama/ollama" target="_blank">Ollama docs</a> for setup instructions.
            </div>
        </div>
        
        <!-- Save Button -->
        <button type="submit" class="btn btn-primary">
            <i class="fas fa-save"></i> Save Ollama Configuration
        </button>
    </form>
</div>

<style>
.input-with-button {
    display: flex;
    gap: 0.5rem;
}

.input-with-button input {
    flex: 1;
}

.input-with-button button {
    white-space: nowrap;
}

#key-status {
    padding: 0.75rem;
    border-radius: 8px;
    font-size: 0.9rem;
}

#key-status.success {
    background: rgba(74, 222, 128, 0.1);
    color: #4ade80;
    border: 1px solid rgba(74, 222, 128, 0.3);
}

#key-status.error {
    background: rgba(248, 113, 113, 0.1);
    color: #f87171;
    border: 1px solid rgba(248, 113, 113, 0.3);
}

.status-card {
    padding: 1rem;
    border-radius: 8px;
    background: var(--bg-secondary);
    border: 1px solid var(--border-color);
}

.example-queries {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
}

.query-category h4 {
    color: var(--primary-color);
    margin-bottom: 0.75rem;
    font-size: 1rem;
}

.query-category ul {
    list-style: none;
    padding: 0;
}

.query-category li {
    padding: 0.5rem 0;
    color: var(--text-secondary);
    font-style: italic;
    border-bottom: 1px solid var(--border-color);
}

.query-category li:last-child {
    border-bottom: none;
}

.required {
    color: #f87171;
}
</style>

<script>
// Handle custom model visibility for Ollama
document.getElementById('ollama-model').addEventListener('change', function() {
    const customGroup = document.getElementById('ollama-custom-model-group');
    customGroup.style.display = this.value === 'custom' ? 'block' : 'none';
});

// Load configurations
async function loadConfig() {
    try {
        const response = await fetch('/api/ai/config');
        const configData = await response.json();
        
        const provider = configData.provider || 'openai';
        
        if (provider === 'openai') {
            // Load OpenAI config
            document.getElementById('openai-enabled').checked = configData.enabled !== false;
            document.getElementById('openai-model').value = configData.model || 'gpt-4o';
            document.getElementById('openai-max-tokens').value = configData.max_tokens || 1000;
            
            if (configData.api_key && configData.api_key !== 'ollama') {
                document.getElementById('openai-api-key').value = '‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè';
            }
        } else {
            // Load Ollama config
            document.getElementById('ollama-enabled').checked = configData.enabled !== false;
            document.getElementById('ollama-base-url').value = configData.base_url || 'http://localhost:11434/v1';
            document.getElementById('ollama-max-tokens').value = configData.max_tokens || 1000;
            
            const ollamaModel = configData.model || 'qwen2.5-coder:7b';
            const modelSelect = document.getElementById('ollama-model');
            const optionExists = Array.from(modelSelect.options).some(opt => opt.value === ollamaModel);
            
            if (optionExists && ollamaModel !== 'custom') {
                modelSelect.value = ollamaModel;
            } else if (ollamaModel !== 'custom') {
                modelSelect.value = 'custom';
                document.getElementById('ollama-custom-model').value = ollamaModel;
                document.getElementById('ollama-custom-model-group').style.display = 'block';
            }
        }
    } catch (error) {
        console.error('Failed to load config:', error);
    }
}

function toggleApiKeyVisibility(provider) {
    const input = document.getElementById(`${provider}-api-key`);
    const icon = document.getElementById(`${provider}-eye-icon`);
    
    if (input.type === 'password') {
        input.type = 'text';
        icon.classList.remove('fa-eye');
        icon.classList.add('fa-eye-slash');
    } else {
        input.type = 'password';
        icon.classList.remove('fa-eye-slash');
        icon.classList.add('fa-eye');
    }
}

function showKeyStatus(provider, type, message) {
    const statusDiv = document.getElementById(`${provider}-key-status`);
    statusDiv.className = type;
    statusDiv.textContent = message;
    statusDiv.style.display = 'block';
    
    setTimeout(() => {
        statusDiv.style.display = 'none';
    }, 5000);
}

async function testOpenAIConnection() {
    const apiKey = document.getElementById('openai-api-key').value;
    const model = document.getElementById('openai-model').value;
    
    if (!apiKey || apiKey === '‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè') {
        showKeyStatus('openai', 'error', '‚ùå Please enter an API key');
        return;
    }
    
    showKeyStatus('openai', 'info', '‚è≥ Testing connection...');
    
    try {
        const response = await fetch('/api/ai/test', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                provider: 'openai',
                api_key: apiKey,
                model: model,
                base_url: 'https://api.openai.com/v1'
            })
        });
        
        const result = await response.json();
        
        if (result.success) {
            showKeyStatus('openai', 'success', '‚úÖ Connection successful! Model: ' + result.model);
        } else {
            showKeyStatus('openai', 'error', '‚ùå Connection failed: ' + result.error);
        }
    } catch (error) {
        showKeyStatus('openai', 'error', '‚ùå Test failed: ' + error.message);
    }
}

async function testOllamaConnection() {
    const baseUrl = document.getElementById('ollama-base-url').value;
    const modelSelect = document.getElementById('ollama-model');
    let model = modelSelect.value;
    
    if (model === 'custom') {
        model = document.getElementById('ollama-custom-model').value;
    }
    
    if (!baseUrl) {
        showKeyStatus('ollama', 'error', '‚ùå Please enter a base URL');
        return;
    }
    
    if (!model) {
        showKeyStatus('ollama', 'error', '‚ùå Please select or enter a model');
        return;
    }
    
    showKeyStatus('ollama', 'info', '‚è≥ Testing connection and checking model...');
    
    try {
        const response = await fetch('/api/ai/test', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                provider: 'ollama',
                base_url: baseUrl,
                model: model
            })
        });
        
        const result = await response.json();
        
        if (result.success) {
            showKeyStatus('ollama', 'success', '‚úÖ ' + result.message);
        } else {
            showKeyStatus('ollama', 'error', '‚ùå ' + result.error);
        }
    } catch (error) {
        showKeyStatus('ollama', 'error', '‚ùå Test failed: ' + error.message);
    }
}

// OpenAI form submission
document.getElementById('openai-config-form').addEventListener('submit', async (e) => {
    e.preventDefault();
    
    const formData = {
        enabled: document.getElementById('openai-enabled').checked,
        provider: 'openai',
        model: document.getElementById('openai-model').value,
        max_tokens: parseInt(document.getElementById('openai-max-tokens').value),
        base_url: 'https://api.openai.com/v1'
    };
    
    // Only include API key if it was changed
    const apiKey = document.getElementById('openai-api-key').value;
    if (apiKey && apiKey !== '‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè') {
        formData.api_key = apiKey;
    }
    
    try {
        const response = await fetch('/api/ai/config', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(formData)
        });
        
        const result = await response.json();
        
        if (result.success) {
            alert('‚úÖ OpenAI configuration saved successfully!');
            await loadConfig();
        } else {
            alert(`‚ùå ${result.error}`);
        }
    } catch (error) {
        alert(`‚ùå Failed to save configuration: ${error?.message || 'Unknown error'}`);
    }
});

// Ollama form submission
document.getElementById('ollama-config-form').addEventListener('submit', async (e) => {
    e.preventDefault();
    
    const formData = {
        enabled: document.getElementById('ollama-enabled').checked,
        provider: 'ollama',
        base_url: document.getElementById('ollama-base-url').value,
        max_tokens: parseInt(document.getElementById('ollama-max-tokens').value),
        api_key: 'ollama'  // Placeholder since Ollama doesn't use keys
    };
    
    // Get model from select or custom input
    const modelSelect = document.getElementById('ollama-model');
    if (modelSelect.value === 'custom') {
        formData.model = document.getElementById('ollama-custom-model').value;
    } else {
        formData.model = modelSelect.value;
    }
    
    try {
        const response = await fetch('/api/ai/config', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(formData)
        });
        
        const result = await response.json();
        
        if (result.success) {
            alert('‚úÖ Ollama configuration saved successfully!');
            await loadConfig();
        } else {
            alert(`‚ùå ${result.error || 'Failed to save configuration'}`);
        }
    } catch (error) {
        alert(`‚ùå Failed to save configuration: ${error?.message || 'Unknown error'}`);
    }
});

// Load config on page load
loadConfig();
</script>
{% endblock %}
